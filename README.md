📖 项目简介
本项目基于对抗攻击研究思想，针对中文欺诈对话检测场景，实现了多种文本扰动方法，以测试和评估简单分类模型的鲁棒性。核心目标是：通过微小的、人类难以察觉的文本修改，使模型产生错误的分类判断。

项目完全基于Python标准库实现，无需安装任何外部依赖，适合快速实验、教学演示和模型安全性初步评估。

🎯 核心特点
特点	说明

🛡️ 无外部依赖	仅使用Python标准库，无需安装nltk、transformers等复杂包

⚡ 完全离线	不依赖网络API或预训练模型下载

📊 实验完整	包含数据加载、模型定义、对抗攻击、结果分析完整流程

🔬 方法多样	实现字符级、词级、句子级共6种文本扰动策略

📈 结果可量化	输出攻击成功率、预测改变率、文本相似度等量化指标

📁 项目结构
fraud_detection_simple/
├── config.py              # 实验配置文件（参数集中管理）
├── data_loader.py         # 数据加载与预处理模块（内置示例数据）
├── simple_model.py        # 基于规则的欺诈对话分类器
├── prompt_attack.py       # 核心对抗攻击算法（6种扰动方法）
├── run_optimized.py       # 主实验脚本（推荐从此开始）
├── README.md              # 项目说明文档
└── results/               # 实验结果输出目录（运行后自动生成）

🚀 快速开始

环境要求

Python 3.6+（无需安装任何额外包）

至少100MB可用磁盘空间（用于保存实验结果）

运行完整实验
只需一步即可运行完整实验流程：
python run_optimized.py

默认会：
加载内置示例数据集
训练简单欺诈检测模型
使用6种扰动方法进行对抗攻击
生成实验结果报告（保存为optimized_results_xxxsamples.txt）
